{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import h5py\n",
    "import numpy as np\n",
    "from functions.preprocess import input_shaping, split_index\n",
    "from functions.decoders import lstm_decoder\n",
    "from functions.metrics import compute_rmse, compute_pearson\n",
    "import time as timer\n",
    "from tensorflow import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting simulation\n"
     ]
    }
   ],
   "source": [
    "seed = 2020 # random seed for reproducibility\n",
    "\n",
    "print (\"Starting simulation\")\n",
    "run_start = timer.time()\n",
    "\n",
    "feature_list = ['sua_rate','mua_rate']\n",
    "feature = feature_list[1] # select which spike feature: SUA=0, MUA=1\n",
    "\n",
    "# specify filename to be processed (choose from the list available at https://zenodo.org/record/583331)\n",
    "file_name = 'indy_20160915_01'          # file name\n",
    "kinematic_folder = 'kinematic_data/'    # kinematic data folder\n",
    "feature_folder = 'spike_data/features/' # spike features folder\n",
    "result_folder = 'results/'              # results folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdw_time = 0.256 # window size in second\n",
    "lag = -32 # lag between kinematic and feature data (minus indicate feature lagging behaind kinematic)\n",
    "delta_time = 0.004 # sampling interval in second\n",
    "wdw_samp = int(round(wdw_time/delta_time))\n",
    "ol_samp = wdw_samp-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data to be processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading input features from file: spike_data/features/indy_20160915_01_spike_features_256ms.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/.local/lib/python3.6/site-packages/h5py/_hl/dataset.py:313: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  \"Use dataset[()] instead.\", H5pyDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# open spike features from hdf5 file\n",
    "feature_file = feature_folder+file_name+'_spike_features_'+str(int(wdw_time*1e3))+'ms.h5'\n",
    "print (\"Loading input features from file: \"+feature_file)\n",
    "with h5py.File(feature_file,'r') as f:\n",
    "    input_feature = f[feature].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading kinematic data from file: kinematic_data/indy_20160915_01_kinematic_data.h5\n"
     ]
    }
   ],
   "source": [
    "# open kinematic data from hdf5 file\n",
    "kinematic_file = kinematic_folder+file_name+'_kinematic_data.h5'\n",
    "print (\"Loading kinematic data from file: \"+kinematic_file)\n",
    "#fields: ['cursor_acc', 'cursor_pos', 'cursor_time', 'cursor_vel', 'target_pos']\n",
    "with h5py.File(kinematic_file,'r') as f:\n",
    "    cursor_vel = f['cursor_vel'].value # in mm/s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the data to fit a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "mm = MinMaxScaler()\n",
    "ss = StandardScaler()\n",
    "\n",
    "\n",
    "X_ss = ss.fit_transform(input_feature)\n",
    "y_mm = mm.fit_transform(cursor_vel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95262, 88) (95262, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_ss.shape, y_mm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first 80,000 for training\n",
    "\n",
    "X_train = X_ss[:80000, :]\n",
    "X_test = X_ss[80000:, :]\n",
    "\n",
    "y_train = y_mm[:80000, :]\n",
    "y_test = y_mm[80000:, :] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Shape (80000, 88) (80000, 2)\n",
      "Testing Shape (15262, 88) (15262, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Shape\", X_train.shape, y_train.shape)\n",
    "print(\"Testing Shape\", X_test.shape, y_test.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjusting the data for pytorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch #pytorch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting nparrays to tensors for pytorch\n",
    "\n",
    "X_train_tensors = Variable(torch.Tensor(X_train))\n",
    "X_test_tensors = Variable(torch.Tensor(X_test))\n",
    "\n",
    "y_train_tensors = Variable(torch.Tensor(y_train))\n",
    "y_test_tensors = Variable(torch.Tensor(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Shape torch.Size([80000, 1, 88]) torch.Size([80000, 2])\n",
      "Testing Shape torch.Size([15262, 1, 88]) torch.Size([15262, 2])\n"
     ]
    }
   ],
   "source": [
    "#reshaping to rows, timestamps, features\n",
    "\n",
    "X_train_tensors_final = torch.reshape(X_train_tensors,   (X_train_tensors.shape[0], 1, X_train_tensors.shape[1]))\n",
    "X_test_tensors_final = torch.reshape(X_test_tensors,  (X_test_tensors.shape[0], 1, X_test_tensors.shape[1]))\n",
    "\n",
    "print(\"Training Shape\", X_train_tensors_final.shape, y_train_tensors.shape)\n",
    "print(\"Testing Shape\", X_test_tensors_final.shape, y_test_tensors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing spytorch functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The coarse network structure is dicated by the Fashion MNIST dataset. \n",
    "nb_inputs  = 88*1\n",
    "nb_hidden  = 100\n",
    "nb_outputs = 2\n",
    "\n",
    "time_step = 1e-3\n",
    "nb_steps  = 100\n",
    "\n",
    "batch_size = 80000\n",
    "\n",
    "dtype = torch.float\n",
    "# Check whether a GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")     \n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init done\n"
     ]
    }
   ],
   "source": [
    "tau_mem = 10e-3\n",
    "tau_syn = 5e-3\n",
    "\n",
    "alpha   = float(np.exp(-time_step/tau_syn))\n",
    "beta    = float(np.exp(-time_step/tau_mem))\n",
    "\n",
    "weight_scale = 7*(1.0-beta) # this should give us some spikes to begin with\n",
    "\n",
    "w1 = torch.empty((nb_inputs, nb_hidden),  device=device, dtype=dtype, requires_grad=True)\n",
    "torch.nn.init.normal_(w1, mean=0.0, std=weight_scale/np.sqrt(nb_inputs))\n",
    "\n",
    "w2 = torch.empty((nb_hidden, nb_outputs), device=device, dtype=dtype, requires_grad=True)\n",
    "torch.nn.init.normal_(w2, mean=0.0, std=weight_scale/np.sqrt(nb_hidden))\n",
    "\n",
    "print(\"init done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def current2firing_time(x, tau=20, thr=0.2, tmax=1.0, epsilon=1e-7):\n",
    "    \"\"\" Computes first firing time latency for a current input x assuming the charge time of a current based LIF neuron.\n",
    "\n",
    "    Args:\n",
    "    x -- The \"current\" values\n",
    "\n",
    "    Keyword args:\n",
    "    tau -- The membrane time constant of the LIF neuron to be charged\n",
    "    thr -- The firing threshold value \n",
    "    tmax -- The maximum time returned \n",
    "    epsilon -- A generic (small) epsilon > 0\n",
    "\n",
    "    Returns:\n",
    "    Time to first spike for each \"current\" x\n",
    "    \"\"\"\n",
    "    idx = x<thr\n",
    "    x = np.clip(x,thr+epsilon,1e9)\n",
    "    T = tau*np.log(x/(x-thr))\n",
    "    T[idx] = tmax\n",
    "    return T\n",
    " \n",
    "\n",
    "def sparse_data_generator(X, y, batch_size, nb_steps, nb_units, sample_size=100,overlap_units=1,shuffle=True ):\n",
    "    \"\"\" This generator takes datasets in analog format and generates spiking network input as sparse tensors. \n",
    "\n",
    "    Args:\n",
    "        X: The data ( sample x event x 2 ) the last dim holds (time,neuron) tuples\n",
    "        y: The labels\n",
    "    \"\"\"\n",
    "\n",
    "    labels_ = np.array(y,dtype=np.int)\n",
    "    number_of_batches = len(X)//batch_size\n",
    "    sample_index = np.arange(0,len(X)-sample_size,overlap_units)\n",
    "\n",
    "#     # compute discrete firing times\n",
    "#     tau_eff = 20e-3/time_step\n",
    "#     firing_times = np.array(current2firing_time(X, tau=tau_eff, tmax=nb_steps), dtype=np.int)\n",
    "#     unit_numbers = np.arange(nb_units)\n",
    "\n",
    "    if shuffle:\n",
    "        np.random.shuffle(sample_index)\n",
    "\n",
    "    total_batch_count = 0\n",
    "    counter = 0\n",
    "    while counter<number_of_batches:\n",
    "        \n",
    "#         for batch_sample_i in range(batch_size):\n",
    "        batch_index = sample_index[batch_size*counter:batch_size*(counter+1)]\n",
    "\n",
    "        \n",
    "        X_batch = np.zeros((batch_size,sample_size,X.shape[-1]))\n",
    "        y_batch = np.zeros((batch_size,y.shape[-1]))\n",
    "        for bc,idx in enumerate(batch_index):\n",
    "            X_batch[idx,:,:] = X[bc:bc+sample_size,:,:].reshape((1,sample_size,X.shape[-1]))\n",
    "            y_batch[idx, :] = y[bc+sample_size,:]\n",
    "            \n",
    "#         i = torch.LongTensor(coo).to(device)\n",
    "#         v = torch.FloatTensor(np.ones(len(coo[0]))).to(device)\n",
    "    \n",
    "        X_batch = torch.FloatTensor(X_batch).to(device)\n",
    "        y_batch = torch.tensor(y_batch,device=device)\n",
    "\n",
    "        yield X_batch.to(device=device), y_batch.to(device=device)\n",
    "\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SurrGradSpike(torch.autograd.Function):\n",
    "    \"\"\"\n",
    "    Here we implement our spiking nonlinearity which also implements \n",
    "    the surrogate gradient. By subclassing torch.autograd.Function, \n",
    "    we will be able to use all of PyTorch's autograd functionality.\n",
    "    Here we use the normalized negative part of a fast sigmoid \n",
    "    as this was done in Zenke & Ganguli (2018).\n",
    "    \"\"\"\n",
    "    \n",
    "    scale = 100.0 # controls steepness of surrogate gradient\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        \"\"\"\n",
    "        In the forward pass we compute a step function of the input Tensor\n",
    "        and return it. ctx is a context object that we use to stash information which \n",
    "        we need to later backpropagate our error signals. To achieve this we use the \n",
    "        ctx.save_for_backward method.\n",
    "        \"\"\"\n",
    "        ctx.save_for_backward(input)\n",
    "        out = torch.zeros_like(input)\n",
    "        out[input > 0] = 1.0\n",
    "        return out\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        \"\"\"\n",
    "        In the backward pass we receive a Tensor we need to compute the \n",
    "        surrogate gradient of the loss with respect to the input. \n",
    "        Here we use the normalized negative part of a fast sigmoid \n",
    "        as this was done in Zenke & Ganguli (2018).\n",
    "        \"\"\"\n",
    "        input, = ctx.saved_tensors\n",
    "        grad_input = grad_output.clone()\n",
    "        grad = grad_input/(SurrGradSpike.scale*torch.abs(input)+1.0)**2\n",
    "        return grad\n",
    "    \n",
    "# here we overwrite our naive spike function by the \"SurrGradSpike\" nonlinearity which implements a surrogate gradient\n",
    "spike_fn  = SurrGradSpike.apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_snn(inputs):\n",
    "    h1 = torch.einsum(\"abc,cd->abd\", (inputs, w1))\n",
    "    syn = torch.zeros((batch_size,nb_hidden), device=device, dtype=dtype)\n",
    "    mem = torch.zeros((batch_size,nb_hidden), device=device, dtype=dtype)\n",
    "\n",
    "    mem_rec = []\n",
    "    spk_rec = []\n",
    "    \n",
    "    print(h1.shape, syn.shape)\n",
    "\n",
    "    # Compute hidden layer activity\n",
    "    for t in range(nb_steps):\n",
    "        if t%5==0:\n",
    "            print(t/nb_steps, ' ', end='')\n",
    "        mthr = mem-1.0\n",
    "        out = spike_fn(mthr)\n",
    "        rst = out.detach() # We do not want to backprop through the reset\n",
    "\n",
    "        new_syn = alpha*syn +h1[:,:,t]\n",
    "#         new_mem = (beta*mem +syn)*(1.0-rst)\n",
    "        new_mem = beta*(mem - rst) + rst + (1 - beta)*syn\n",
    "\n",
    "        mem_rec.append(mem)\n",
    "        spk_rec.append(out)\n",
    "        \n",
    "        mem = new_mem\n",
    "        syn = new_syn\n",
    "    print('')\n",
    "\n",
    "    mem_rec = torch.stack(mem_rec,dim=1)\n",
    "    spk_rec = torch.stack(spk_rec,dim=1)\n",
    "    \n",
    "    print(spk_rec.shape)\n",
    "#     nn.Linear(s, 128)\n",
    "\n",
    "    # Readout layer - make into different module, and then make a new module that's a NN module\n",
    "    h2= torch.einsum(\"abc,cd->abd\", (spk_rec, w2))\n",
    "    flt = torch.zeros((batch_size,nb_outputs), device=device, dtype=dtype)\n",
    "    out = torch.zeros((batch_size,nb_outputs), device=device, dtype=dtype)\n",
    "    out_rec = [out]\n",
    "    for t in range(nb_steps):\n",
    "        new_flt = alpha*flt +h2[:,t]\n",
    "        new_out = beta*out +flt\n",
    "\n",
    "        flt = new_flt\n",
    "        out = new_out\n",
    "\n",
    "        out_rec.append(out)\n",
    "\n",
    "    out_rec = torch.stack(out_rec,dim=1)\n",
    "    other_recs = [mem_rec, spk_rec]\n",
    "    return out_rec, other_recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x_data, y_data, lr=2e-3, nb_epochs=10):\n",
    "    params = [w1,w2]\n",
    "    optimizer = torch.optim.Adam(params, lr=lr, betas=(0.9,0.999))\n",
    "\n",
    "    log_softmax_fn = nn.LogSoftmax(dim=1)\n",
    "    loss_fn = nn.MSELoss()\n",
    "    \n",
    "    loss_hist = []\n",
    "    for e in range(nb_epochs):\n",
    "        print('Epoch number:', e)\n",
    "        local_loss = []\n",
    "        for x_local, y_local in sparse_data_generator(x_data, y_data, batch_size, nb_steps, nb_inputs):\n",
    "#             output,_ = run_snn(x_local.to_dense()) #use when access to gpu is available\n",
    "            output,_ = run_snn(x_local)\n",
    "            m,_=torch.max(output,1)\n",
    "            log_p_y = log_softmax_fn(m)\n",
    "            loss_val = loss_fn(log_p_y, y_local)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss_val.backward()\n",
    "            optimizer.step()\n",
    "            local_loss.append(loss_val.item())\n",
    "        mean_loss = np.mean(local_loss)\n",
    "        print(\"Epoch %i: loss=%.5f\"%(e+1,mean_loss))\n",
    "        loss_hist.append(mean_loss)\n",
    "        \n",
    "    return loss_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number: 0\n",
      "torch.Size([80000, 100, 100]) torch.Size([80000, 100])\n",
      "0.0  0.05  0.1  0.15  0.2  0.25  0.3  "
     ]
    }
   ],
   "source": [
    "loss_hist = train(X_train_tensors_final, y_train_tensors, lr=2e-4, nb_epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM1(nn.Module):\n",
    "  def __init__(self, num_classes, input_size, hidden_size, num_layers, seq_length):\n",
    "    super(LSTM1, self).__init__()\n",
    "    self.num_classes = num_classes #number of classes\n",
    "    self.num_layers = num_layers #number of layers\n",
    "    self.input_size = input_size #input size\n",
    "    self.hidden_size = hidden_size #hidden state\n",
    "    self.seq_length = seq_length #sequence length\n",
    " \n",
    "    self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
    "                      num_layers=num_layers, batch_first=True) #lstm\n",
    "    self.fc_1 =  nn.Linear(hidden_size, 128) #fully connected 1\n",
    "    self.fc = nn.Linear(128, num_classes) #fully connected last layer\n",
    "\n",
    "    self.relu = nn.ReLU() \n",
    "    \n",
    "  def forward(self,x):\n",
    "    h_0 = Variable(torch.zeros(\n",
    "          self.num_layers, x.size(0), self.hidden_size)) #hidden state\n",
    "     \n",
    "    c_0 = Variable(torch.zeros(\n",
    "        self.num_layers, x.size(0), self.hidden_size)) #internal state\n",
    "   \n",
    "    # Propagate input through LSTM\n",
    "\n",
    "    output, (hn, cn) = self.lstm(x, (h_0, c_0)) #lstm with input, hidden, and internal state\n",
    "   \n",
    "    hn = hn.view(-1, self.hidden_size) #reshaping the data for Dense layer next\n",
    "\n",
    "    out = self.relu(hn)\n",
    "\n",
    "    out = self.fc_1(out) #Fully connected layer\n",
    "\n",
    "    out = self.relu(out) #relu\n",
    "\n",
    "    out = self.fc(out) #Final Output\n",
    "   \n",
    "    return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100 #1000 epochs\n",
    "learning_rate = 0.001 #0.001 lr\n",
    "\n",
    "input_size = 88 #number of features\n",
    "hidden_size = 32 #number of features in hidden state\n",
    "num_layers = 1 #number of stacked lstm layers\n",
    "\n",
    "num_classes = 2 #number of output classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm1 = LSTM1(num_classes, input_size, hidden_size, num_layers, X_train_tensors_final.shape[1]) #our lstm class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss()    # mean-squared error for regression\n",
    "optimizer = torch.optim.Adam(lstm1.parameters(), lr=learning_rate) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the LSTM on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 0.26248\n",
      "Epoch: 10, loss: 0.13260\n",
      "Epoch: 20, loss: 0.03459\n",
      "Epoch: 30, loss: 0.02424\n",
      "Epoch: 40, loss: 0.01293\n",
      "Epoch: 50, loss: 0.00917\n",
      "Epoch: 60, loss: 0.00753\n",
      "Epoch: 70, loss: 0.00649\n",
      "Epoch: 80, loss: 0.00583\n",
      "Epoch: 90, loss: 0.00531\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "  outputs = lstm1.forward(X_train_tensors_final) #forward pass\n",
    "  optimizer.zero_grad() #caluclate the gradient, manually setting to 0\n",
    " \n",
    "  # obtain the loss function\n",
    "  loss = criterion(outputs, y_train_tensors)\n",
    " \n",
    "  loss.backward() #calculates the loss of the loss function\n",
    " \n",
    "  optimizer.step() #improve from loss, i.e backprop\n",
    "  if epoch % 10 == 0:\n",
    "    print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0055, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(criterion(lstm1.forward(X_test_tensors_final), y_test_tensors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
